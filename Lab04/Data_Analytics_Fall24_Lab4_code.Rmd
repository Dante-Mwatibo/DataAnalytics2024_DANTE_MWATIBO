# Principal Component Analysis (PCA)

```{r setup, include=FALSE}
# Required R package installation:

# These will install packages if they are not already installed
if (!require("devtools")) {
   install.packages("devtools")
   library(devtools)
}

if (!require("ggplot2")) {
   install.packages("ggplot2")
   library(ggplot2)
}
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}
if (!require("gplots")) {
   install.packages("gplots")
   library(gplots)
}
if (!require("ggbiplot")) {
   devtools::install_git("https://github.com/vqv/ggbiplot.git")
   library(ggbiplot)
}
  if (!require("dplyr")) {
   install.packages("dplyr")
   library(dplyr)
  }

  if (!require("ggdendro")) {
   install.packages("ggdendro")
   library(ggdendro)
  }
  if (!require("plotly")) {
   install.packages("plotly")
   library(plotly)
  }
  if (!require("heatmaply")) {
   install.packages("heatmaply")
   library(heatmaply)
  }

if (!require("pheatmap")) {
 install.packages("pheatmap")
  library(pheatmap)
  }
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggfortify)
library(e1071)
library(class)
library(psych)
library(ggbiplot)
library(utils)

# PCA with iris dataset
wine <- read.csv("wine.data")
names(wine) <- c("Type","Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid Phenols","Proanthocyanins","Color Intensity","Hue","Od280/od315 of diluted wines","Proline")
head(wine)

wine$Type <- as.factor(wine$Type)

wine <- wine[,-c(4,5,10)]

pairs.panels(wine[,-1],gap = 0,bg = c("red", "yellow", "blue")[wine$Type],pch=21)
```


# Compute the PCs and plot the dataset using the 1st and 2nd PC
```{r}
wine.pc <- prcomp(wine[,-1], center = TRUE, scale. = TRUE)
ggbiplot(as.data.frame(wine.pc$x[,c(1,2)]), labels=rownames(wine),
                var.axes=TRUE, obs.scale=1)
ggtitle("Consumer Data Projected on PC1 and PC2 ")
```


# Identify the variables that contribute the most to the 1st PC
```{r}
wine.pc$rotation[,1]
```
According to the data the variables that contribute the most to the 1st PC are: flavanoids, total phenols, and Od280/od315 of diluted wines. This is because they have the highest absolute value in wine.pc$rotation, which means they have the highest influence in determining the number PC1 comes out to


# Train a classifier model to predict wine type using the 13 attributes
```{r}
classifier.raw <- naiveBayes(wine[,-1], wine[,1])
prediction.raw <- predict(classifier.raw, wine[,-1])
table(prediction.raw, wine[,1], dnn=list('predicted','actual'))
```

# Train a classifier model to predict wine type using the data projected into the first 3 PCs.
```{r}
classifier2.pca <- naiveBayes(wine.pc$x[,1:3], wine[,1])
prediction2.pca <- predict(classifier2.pca, wine.pc$x[,1:3])
table(prediction2.pca, wine[,1], dnn=list('predicted','actual'))
```


# Drop the variables least contributing to the 1st PC and rerun PCA.
```{r}
wine.pc$rotation[,1]
wine2 <- wine[,c(1,3:7,9:11)]
wine2.pc <- prcomp(wine2[,-1], center = TRUE, scale. = TRUE)
```
Because Alcohol and Color Intensity are the least contributing to the 1st PC, I will drop this and rerun PCA.


# Train a classifier model to predict wine type using the data projected into the first 3 PCs.
```{r}
classifier3.pca <- naiveBayes(wine2.pc$x[,1:3], wine2[,1])
prediction3.pca <- predict(classifier3.pca, wine2.pc$x[,1:3])
table(prediction3.pca, wine[,1], dnn=list('predicted','actual'))
```

# Compare the 3 classification models using contingency tables and prevision/recall/f1metrics
```{r}
table(prediction.raw, wine[,1], dnn=list('predicted','actual'))
table(prediction2.pca, wine[,1], dnn=list('predicted','actual'))
table(prediction3.pca, wine[,1], dnn=list('predicted','actual'))
```


# Compare the 3 classification models using prevision/recall/f1metrics
```{r}
# getting the precision/recall/f1 for the first classification model
cm.1 = as.matrix(table(Actual = wine$Type, Predicted = prediction.raw))

cm.1

n = sum(cm.1) # number of instances
nc = nrow(cm.1) # number of classes
diag = diag(cm.1) # number of correctly classified instances per class 
rowsums = apply(cm.1, 1, sum) # number of instances per class
colsums = apply(cm.1, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 

recall.1 = diag / rowsums 
precision.1 = diag / colsums
f1.1 = 2 * precision.1 * recall.1 / (precision.1 + recall.1) 

data.frame(precision.1, recall.1, f1.1)


# getting the precision/recall/f1 for the second classification model
cm.2 = as.matrix(table(Actual = wine$Type, Predicted = prediction2.pca))

cm.2

n = sum(cm.2) # number of instances
nc = nrow(cm.2) # number of classes
diag = diag(cm.2) # number of correctly classified instances per class 
rowsums = apply(cm.2, 1, sum) # number of instances per class
colsums = apply(cm.2, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 

recall.2 = diag / rowsums 
precision.2 = diag / colsums
f1.2 = 2 * precision.2 * recall.2 / (precision.2 + recall.2) 

data.frame(precision.2, recall.2, f1.2)


# getting the precision/recall/f1 for the third classification model
cm.3 = as.matrix(table(Actual = wine$Type, Predicted = prediction3.pca))

cm.3

n = sum(cm.3) # number of instances
nc = nrow(cm.3) # number of classes
diag = diag(cm.3) # number of correctly classified instances per class 
rowsums = apply(cm.3, 1, sum) # number of instances per class
colsums = apply(cm.3, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 

recall.3 = diag / rowsums 
precision.3 = diag / colsums
f1.3 = 2 * precision.3 * recall.3 / (precision.3 + recall.3) 

data.frame(precision.3, recall.3, f1.3)
```
It appears that while the naiveBayes after PCA processing and dropping the fields that yield the worst results overall. The naiveBayes with the first 3 PCAs and the naiveBayes with the raw data appear to have some tradeoff, so whichever Type is most important to the client to get correct would sway my decision on which classifier to deploy. That being said, with the numbers as high as they are it is important to be carefull of overfitting.
